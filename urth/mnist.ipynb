{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGaJxAq9jEOw"
      },
      "source": [
        "\n",
        "# Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpT-tFRzCMvi",
        "outputId": "aafc987a-1d7e-4210-96a7-2139e81244bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e51e8ecba10>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from copy import deepcopy\n",
        "\n",
        "# Set a seed for reproducibility\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install onnx\n",
        "import onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIaX-pQIGSsw",
        "outputId": "b0ef278a-8de8-4aba-f46c-49d7f5bddc74"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.14.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeAuE1TzjAtR"
      },
      "source": [
        "# Define the neural network, load data, train it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yoe-IsTCQW7",
        "outputId": "392a822f-d4a6-490a-d579-e909ac5a3ff2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.305925\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.763578\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.358299\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.339006\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.307977\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.307055\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.416261\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.290539\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.173276\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.308258\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.322455\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.230289\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.308662\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.312016\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.149674\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.197216\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.182512\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.360825\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.152675\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.116809\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.172685\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.147442\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.065834\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.179185\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.129309\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.160169\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.169994\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.201553\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.119437\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.145129\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.158931\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.052205\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.184734\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.092108\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.055889\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.071725\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.169676\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.078485\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.204323\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.024554\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.114632\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.140726\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.034848\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.149469\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.102977\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.056241\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.061885\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.051227\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.139481\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.054017\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.112805\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.021717\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.048922\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.096806\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.036381\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.058742\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.171356\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.109858\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.158656\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.140405\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.086106\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.050062\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.125294\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.107477\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.020484\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.053520\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.041226\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.121618\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.016091\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.022835\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.058469\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.039672\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.016069\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.019058\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.043340\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.111530\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.070717\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.092738\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.130241\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.046720\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.043664\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.034956\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.031176\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.036535\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.058737\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.034970\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.080821\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.077908\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.025718\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.082434\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.052222\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.020920\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.038822\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.054167\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.062574\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.029881\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.031587\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.040439\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.022087\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.010280\n"
          ]
        }
      ],
      "source": [
        "# Define a simple neural network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Set the device to use for computation\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set up the network and optimizer\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Load the training data\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('./data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                #       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])\n",
        "    ),\n",
        "    batch_size=64, shuffle=True)\n",
        "\n",
        "# Train the model\n",
        "model.train()\n",
        "for epoch in range(10):  # 10 epochs\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data = data\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = nn.CrossEntropyLoss()(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUESWKlvBW1_"
      },
      "source": [
        "# Create the test loader and test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pKORePvqIQqj"
      },
      "outputs": [],
      "source": [
        "# Load the test data\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('./data', train=False,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                   #    transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])\n",
        "    ),\n",
        "    batch_size=1000, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_5cjxf_BJTb",
        "outputId": "642c91e4-afcd-4320-ead8-2c71942754ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 969/10000 (10%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()  # set the model to evaluation mode\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():  # disable gradient computation\n",
        "        for data, target in test_loader:\n",
        "            data = torch.round(data)\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += nn.CrossEntropyLoss()(output, target).item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            break\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "test(model, device, test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qniMb94VjMnN"
      },
      "source": [
        "# Construct and train an Observer Model.\n",
        "\n",
        "This network records the maximum and minimum output value of each layer in the training set when loaded with the learned weights from the previous step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf9F7HCLg54g",
        "outputId": "1ed847c8-c74b-4ffe-9665-a1570bb70e1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 63/60000 (0%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class ObserveNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ObserveNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "        self.so_1_max = torch.tensor(-float('inf'))\n",
        "        self.so_2_max = torch.tensor(-float('inf'))\n",
        "        self.so_1_min = torch.tensor(float('inf'))\n",
        "        self.so_2_min = torch.tensor(float('inf'))\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.view(-1, 784)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "\n",
        "        temp_max = torch.max(x)\n",
        "        temp_min = torch.min(x)\n",
        "        self.so_1_max = temp_max if temp_max > self.so_1_max else self.so_1_max\n",
        "        self.so_1_min = temp_min if temp_min < self.so_1_min else self.so_1_min\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        temp_max = torch.max(x)\n",
        "        temp_min = torch.min(x)\n",
        "        self.so_2_max = temp_max if temp_max > self.so_2_max else self.so_2_max\n",
        "        self.so_2_min = temp_min if temp_min < self.so_2_min else self.so_2_min\n",
        "\n",
        "        return x\n",
        "\n",
        "q_model_dict = deepcopy(model.state_dict())\n",
        "\n",
        "o_net = ObserveNet()\n",
        "o_net.load_state_dict(q_model_dict)\n",
        "\n",
        "test(o_net, device, train_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9Bgm74tjcF_"
      },
      "source": [
        "# Calculate scale constants of output for layer1 and layer2\n",
        "\n",
        "We calculate the output scale for layer1 and layer2 using the maximum and minimum output values for each layer gathered by the Observer network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZN2ZHzvhm0X",
        "outputId": "a4d9f273-85a8-4931-e007-61945005a809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.04499745181226355\n",
            "0.14810363889679196\n"
          ]
        }
      ],
      "source": [
        "so_1 = max(o_net.so_1_max, torch.abs(o_net.so_1_min)).float().item() / 127\n",
        "so_2 = max(o_net.so_2_max, torch.abs(o_net.so_2_min)).float().item() / 127\n",
        "print(so_1)\n",
        "print(so_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ87k5mRjk1X"
      },
      "source": [
        "# Quantize the layer weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsC8AvHLldko",
        "outputId": "ad99458d-b179-48fe-8a58-469a48b8f994"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from copy import deepcopy\n",
        "q_model_dict = deepcopy(model.state_dict())\n",
        "\n",
        "# Returns the maximum value of a tensor devided by `m` which is the maximum n-bit int value\n",
        "# in quantization range.\n",
        "def max_scale(x: torch.tensor, m: int):\n",
        "  return torch.max(torch.abs(x)).item()/m\n",
        "\n",
        "# Scale of fc1 and fc2 determined by maximum value of int8 (127) and maximum weight value.\n",
        "def quantize_fc(x: torch.tensor, m: int):\n",
        "  return max_scale(x,m), torch.round(x / max_scale(x, m)).to(dtype=torch.int32)\n",
        "\n",
        "# Scale of bias determined by scale of the output of fc layer\n",
        "# Which is the scale of input multiplied by scale of the fc layer.\n",
        "def quantize_bias(x: torch.tensor, s: float):\n",
        "  # saturate\n",
        "  return torch.clip(torch.round(x/s), min=-127, max=127)\n",
        "\n",
        "s_fc1, q_model_dict['fc1.weight'] = quantize_fc(q_model_dict['fc1.weight'], 127)\n",
        "q_model_dict['fc1.bias'] = quantize_bias(q_model_dict['fc1.bias'], s_fc1 * 1 / 127)\n",
        "s_fc2, q_model_dict['fc2.weight'] = quantize_fc(q_model_dict['fc2.weight'], 127)\n",
        "q_model_dict['fc2.bias'] = quantize_bias(q_model_dict['fc2.bias'], s_fc2*so_1)\n",
        "\n",
        "class QuantNet(nn.Module):\n",
        "    def __init__(self, s_fc1, s_fc2, so_1, so_2):\n",
        "        super(QuantNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "        self.s_fc1 = s_fc1\n",
        "        self.s_fc2 = s_fc2\n",
        "        self.so_1 = so_1\n",
        "        self.so_2 = so_2\n",
        "        self.s_x = 1 / 127\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "\n",
        "        # Scale input\n",
        "        x = torch.round(x / self.s_x)\n",
        "\n",
        "        # First layer\n",
        "        x = torch.relu(self.fc1(x))\n",
        "\n",
        "        # Requantize and saturation cast\n",
        "        x = torch.clip(torch.round(x * ((self.s_fc1 * self.s_x) / self.so_1)), -127, 127)\n",
        "\n",
        "        # Second layer\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # Requantize and saturation cast\n",
        "        x = torch.clip(torch.round(x * ((self.s_fc2 * self.so_1) / self.so_2)), -127, 127)\n",
        "\n",
        "        return x * self.so_2\n",
        "\n",
        "q_net = QuantNet(s_fc1=s_fc1, s_fc2=s_fc2, so_1=so_1, so_2=so_2)\n",
        "q_net.load_state_dict(q_model_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GLzj2kilCSu"
      },
      "source": [
        "# Print the scaling values so they can be used inside of Urbit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyzedMfi9u02",
        "outputId": "866edd4c-1650-4c75-e99c-b8e8f9f8a2ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.04499745181226355\n",
            "0.14810363889679196\n",
            "0.0019561668315271692\n",
            "0.0059992356563177635\n"
          ]
        }
      ],
      "source": [
        "print(so_1)\n",
        "print(so_2)\n",
        "print(s_fc1)\n",
        "print(s_fc2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1fBABBmktOw"
      },
      "source": [
        "# Test the QuantNet on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S0Q85t0C266",
        "outputId": "b360165e-f869-40c4-e12c-2835f3cd63d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 973/10000 (10%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Run the test function\n",
        "test(q_net, device, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = list(test_loader)[0][0][0]"
      ],
      "metadata": {
        "id": "tFxYUypJMyJb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run cells below to export model to onnx\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DhF5aNxy9Svz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hqmS_KecUxNJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8084cbcc-d9cf-4150-9925-7bd1842e867a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "torch.onnx.export(q_net,               # model being run\n",
        "                  x[0],                         # model input (or a tuple for multiple inputs)\n",
        "                  \"net-quant.onnx\",   # where to save the model (can be a file or file-like object)\n",
        "                  export_params=True,        # store the trained parameter weights inside the model file\n",
        "                  opset_version=11,          # the ONNX version to export the model to\n",
        "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "                  input_names = ['input1'],   # the model's input names\n",
        "                  output_names = ['output'], # the model's output names\n",
        "                  dynamic_axes={'input1' : {0 : 'input_size'},    # variable length axes\n",
        "                                'output' : {0 : 'input_size'}})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = onnx.load('net-quant.onnx')\n",
        "weights = model.graph.initializer\n",
        "onnx.numpy_helper.to_array(weights[2]).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mf7lqOswGk9u",
        "outputId": "e31575b0-8ae3-4e81-c800-423a1ee5fb7d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSS5OZSDkwyh"
      },
      "source": [
        "# Write the QuantNet weights to disk as int32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em2AFkF2FU1m",
        "outputId": "1b4f42ba-3274-4aa1-816f-75d371e8a0b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fc1.weight\n",
            "[[  9  -8  -4 ...   3  -2   1]\n",
            " [-14 -11 -16 ...  -1   1  -9]\n",
            " [ 14  -5 -17 ...  -7   3 -17]\n",
            " ...\n",
            " [ 16 -10 -16 ...   7 -14   9]\n",
            " [  8 -11 -14 ...  -9 -17  13]\n",
            " [ 13 -17 -12 ...  18   4  11]]\n",
            "fc1.bias\n",
            "[ 127 -127  127 -127  127  127  127  127  127 -127 -127  127  127  127\n",
            " -127  127  127 -127  127  127  127  127  127 -127  127  127 -127 -127\n",
            "  127 -127  127 -127 -127 -127 -127  127 -127  127  127  127  127 -127\n",
            " -127  127 -127 -127  127 -127 -104  127  127  127 -127  127 -127  127\n",
            " -127  127 -127 -127  127  127  127  127 -127  127 -127  127  127  127\n",
            "  127  127 -127  127  127  127 -127  127  127  127 -127  127  127 -127\n",
            "  127  127  127  127 -127 -127 -127 -127 -127  127   56 -127  127  127\n",
            "  127  127  127 -127  127  127 -127  127  127 -127  127  127  127 -127\n",
            "  127 -127  127 -127  127  127  127 -127 -127  127 -127  127  -42  127\n",
            "  127  127 -127  127  127  127 -127  127  127  127  127  127  127  127\n",
            "  127  127  127  127  127  127  127 -127 -127  127  127  127 -127 -127\n",
            "  127  127  127 -127  127  127 -127  127  127 -127 -127  127 -127  127\n",
            " -127  127 -127  127  127   63 -127 -127 -127  127  127  127  127  127\n",
            "  127  127  127 -127  127  127  127 -127  127  127  127 -127  127  127\n",
            "  127 -127  127  127 -127  127  127  127  127 -127  127  127  127 -127\n",
            " -127  127 -127  127 -127  127  127 -127  127  127  127  127 -127  127\n",
            "  -32  127 -127 -127 -127 -127 -127  127 -127  127  127  127  127  127\n",
            "  127  127 -127 -127  127 -127  127  127 -127  127  127 -127  127 -127\n",
            "  127 -127  127  127  127  127  127  127 -127 -127  127  127  127 -127\n",
            "  127 -127  127 -127  127  127 -127 -127 -127  127  127 -127  127 -127\n",
            "  127 -127 -127  127 -127  127  127  127  127 -127  127 -127  127  127\n",
            "  127  127  127  127  127 -127 -127 -127  109  127 -127  127 -127  127\n",
            "  127 -127  127 -127  -84  127 -127  127 -127 -127  127  127  127  127\n",
            "  127  127 -127 -127 -127 -127  127 -127 -127 -127  127 -127  127  127\n",
            " -127  127  127  127 -127  127  127  127  -74  127  127  127 -127  127\n",
            " -127 -127  127  127 -127 -127 -127  127 -127  127 -127   18  127  127\n",
            "  127 -127  127 -127 -127  127  127  127  127  127 -127  127  127  127\n",
            "  127  127 -127  127 -127  127  127 -127 -127 -127  127  127 -127  127\n",
            " -127  127  127  127 -127  127  127 -127  127  127  127 -127  127 -127\n",
            " -127  127 -127  127  127  127 -127  127  127  127  127  127  127 -127\n",
            " -127 -127  127  127  -56 -127  127  127  127  127 -127 -127  127  127\n",
            "  127  127 -127 -127 -127 -127  127  127  127  127 -127  127   63  127\n",
            "  127 -127  127  127 -127  127  127 -127  127  127 -127  127  127  127\n",
            "  127  127  127  127 -127  127 -127  127  127 -127 -127  127 -127   81\n",
            "  127 -127  127  127 -127 -127  127 -127  127 -127  127  127 -127  127\n",
            "  127 -127  127 -127  127 -127 -127  127  127  127]\n",
            "fc2.weight\n",
            "[[ 36 -20 -14 ... -29  10  17]\n",
            " [-23  65  10 ...  17 -25  25]\n",
            " [-26  -9 -24 ... -10 -10  17]\n",
            " ...\n",
            " [ 44   6 -12 ...  -5   1  24]\n",
            " [-33 -24 -31 ...   0 -20 -37]\n",
            " [-11 -31 -22 ...   5  -8  -1]]\n",
            "fc2.bias\n",
            "[-127  127 -127 -127  127  127  -88  127 -127  -91]\n"
          ]
        }
      ],
      "source": [
        "for name, param in q_net.named_parameters():\n",
        "    print(name)\n",
        "    print(param.detach().int().numpy())\n",
        "    def to_byte_array(array, name):\n",
        "        # Ensure the array is int32\n",
        "        array = array.astype(np.int32)\n",
        "\n",
        "        # Flatten the array in column-major order\n",
        "        flattened = array.flatten(order='C')\n",
        "\n",
        "        # Convert to byte array\n",
        "        byte_array = flattened.tobytes()\n",
        "\n",
        "        # Write byte array to a file\n",
        "        with open(name, 'wb') as f:\n",
        "          f.write(byte_array)\n",
        "\n",
        "\n",
        "        return byte_array\n",
        "\n",
        "    # Test the function\n",
        "    to_byte_array(param.detach().int().numpy(), f'{name}.mnist')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TzK-E7dWNC7F"
      },
      "execution_count": 14,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}